import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util

# === ä½¿ç”¨æ—¥æ–‡ Sentence-BERT æ¨¡å‹ï¼Œå¼·åˆ¶ä½¿ç”¨ CPU é¿å…éƒ¨ç½²éŒ¯èª¤ ===
model = SentenceTransformer("sonoisa/sentence-bert-base-ja-mean-tokens", device="cpu")

# === æ¯ç¨®é¡å‹çš„ä¸‰å¥å®šç¾©èªå¥ ===
default_definitions = {
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŒ‘æˆ¦å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ç§ãŸã¡ã¯ãƒ¢ãƒ“ãƒªãƒ†ã‚£ã‚µãƒ¼ãƒ“ã‚¹ä¼æ¥­ã¸ã¨è»¢æ›ã—ã¾ã™ã€‚\n"
        "æ–°ã—ã„ç¤¾ä¼šèª²é¡Œã«æŒ‘ã‚€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ä¼æ¥­ã¸ç”Ÿã¾ã‚Œå¤‰ã‚ã‚Šã¾ã™ã€‚\n"
        "å½“ç¤¾ã®ä½¿å‘½ã‚’å†å®šç¾©ã—ã€ãƒ‡ã‚¸ã‚¿ãƒ«æ™‚ä»£ã®ä¾¡å€¤å‰µé€ ä¼æ¥­ã¨ãªã‚Šã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ‹¡å¼µå‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ä¼çµ±ã®æŠ€è¡“åŠ›ã‚’æ–°é ˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¸å¿œç”¨ã—ã¾ã™ã€‚\n"
        "ã‚³ã‚¢ãƒãƒªãƒ¥ãƒ¼ã‚’ä¿ã¡ãªãŒã‚‰ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢å¸‚å ´ã¸äº‹æ¥­ã‚’åºƒã’ã¾ã™ã€‚\n"
        "ã‚‚ã®ã¥ãã‚Šç²¾ç¥ã‚’IoTã‚µãƒ¼ãƒ“ã‚¹ã«èåˆã•ã›ã€æ–°ãŸãªä¾¡å€¤ã‚’æä¾›ã—ã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£å¼·åŒ–å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "é«˜å“è³ªã¸ã®ã“ã ã‚ã‚Šã‚’ã•ã‚‰ã«ç£¨ãæ—¢å­˜è£½å“ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n"
        "ç’°å¢ƒå¿—å‘ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚è³‡æºå¾ªç’°å‹å·¥ç¨‹ã‚’å°å…¥ã—ã¾ã™ã€‚\n"
        "é•·å¹´åŸ¹ã£ãŸå®‰å…¨æ€§ã‚’æ ¸ã«æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¾ã™ã€‚"
    ),
    "ä¼çµ±çš„ï¼ä¸­ç«‹çš„è¨€èª": (
        "ç”Ÿç”£åŠ¹ç‡ã‚’7%å‘ä¸Šã•ã›ã‚‹æ”¹å–„æ´»å‹•ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚\n"
        "ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã«ã‚ˆã‚Šå–¶æ¥­åˆ©ç›Šç‡ãŒä¸Šæ˜‡ã—ã¾ã—ãŸã€‚\n"
        "å“è³ªç®¡ç†ä½“åˆ¶ã‚’å†æ§‹ç¯‰ã—ä¸è‰¯ç‡ã‚’å‰Šæ¸›ã—ã¾ã—ãŸã€‚"
    ),
    "ãã®ä»–ï¼ˆOtherï¼‰": (
        "ä»Šå¹´åº¦ã®å¯„ä»˜é‡‘ç·é¡ã¯1å„„å††ã¨ãªã‚Šã¾ã—ãŸã€‚\n"
        "æ–°ã—ã„ç¦åˆ©åšç”Ÿåˆ¶åº¦ã‚’å°å…¥ã—ã¾ã—ãŸã€‚\n"
        "äº‹å‹™æ‰€ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’å¤‰æ›´ã—ã¾ã—ãŸã€‚"
    )
}

# === Streamlit UI è¨­å®š ===
st.set_page_config(page_title="æ—¥æœ¬èªå¥å­åˆ†é¡", layout="centered")
st.title("ğŸ“Š æ—¥æœ¬èªï¼šä¼æ¥­å¹´å ±æ–‡ã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡")

# === åˆ†é¡å®šç¾©è¼¸å…¥å€ ===
st.header("ğŸ“ åˆ†é¡åŸºæº–ã®å®šç¾©æ–‡ï¼ˆå„ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«è¤‡æ•°è¡Œã§å…¥åŠ›ï¼‰")
category_inputs = {}
for cat, default in default_definitions.items():
    category_inputs[cat] = st.text_area(
        cat,
        value=default,
        height=90,
        help="æ”¹è¡Œã”ã¨ã«åˆ¥ã®å®šç¾©æ–‡ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™"
    )

# === åˆ†æå¥å­è¼¸å…¥å€ ===
st.header("âœï¸ åˆ†æå¯¾è±¡ã®æ–‡ã‚’å…¥åŠ›ï¼ˆ1 è¡Œ 1 æ–‡ï¼‰")
sentences_text = st.text_area("ã“ã“ã«æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=220)

# === åˆ†ææŒ‰éˆ• ===
if st.button("ğŸš€ åˆ†æã™ã‚‹"):
    sentences = [s.strip() for s in sentences_text.splitlines() if s.strip()]
    if not sentences:
        st.warning("æ–‡ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)

    # å¤šå¥å®šç¾©èªå¥å¹³å‡å‘é‡è™•ç†
    definition_embeddings = {}
    for label, text_block in category_inputs.items():
        defs = [t.strip() for t in text_block.splitlines() if t.strip()]
        if not defs:
            defs = default_definitions[label].splitlines()
        emb = model.encode(defs, convert_to_tensor=True).mean(dim=0)
        definition_embeddings[label] = emb

    # ç›¸ä¼¼åº¦è¨ˆç®—èˆ‡åˆ†é¡
    predicted_labels, similarity_scores = [], []
    for sent_emb in sentence_embeddings:
        scores = {
            label: float(util.cos_sim(sent_emb, def_emb))
            for label, def_emb in definition_embeddings.items()
        }
        best_label = max(scores, key=scores.get)
        predicted_labels.append(best_label)
        similarity_scores.append(scores[best_label])

    # é¡¯ç¤ºçµæœ
    result_df = pd.DataFrame({
        "å…¥åŠ›æ–‡": sentences,
        "åˆ†é¡ãƒ©ãƒ™ãƒ«": predicted_labels,
        "similarity score": similarity_scores
    })
    st.subheader("ğŸ” åˆ†æçµæœ")
    st.dataframe(result_df, use_container_width=True)
