import streamlit as st
import pandas as pd
import torch
from sentence_transformers import SentenceTransformer, util

# æ¨¡å‹è¼‰å…¥
model = SentenceTransformer("sonoisa/sentence-bert-base-ja-mean-tokens")

# åˆ†é¡å®šç¾©æ–‡ï¼ˆå·²ç°¡åŒ–ç‚º4é¡ï¼‰
category_definitions = {
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŒ‘æˆ¦å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ç§ãŸã¡ã¯ãƒ¢ãƒ“ãƒªãƒ†ã‚£ã‚µãƒ¼ãƒ“ã‚¹ä¼æ¥­ã¸ã¨è»¢æ›ã—ã¾ã™ã€‚\n"
        "æ–°ã—ã„ç¤¾ä¼šèª²é¡Œã«æŒ‘ã‚€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ä¼æ¥­ã¸ç”Ÿã¾ã‚Œå¤‰ã‚ã‚Šã¾ã™ã€‚\n"
        "å½“ç¤¾ã®ä½¿å‘½ã‚’å†å®šç¾©ã—ã€ãƒ‡ã‚¸ã‚¿ãƒ«æ™‚ä»£ã®ä¾¡å€¤å‰µé€ ä¼æ¥­ã¨ãªã‚Šã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ‹¡å¼µå‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ä¼çµ±ã®æŠ€è¡“åŠ›ã‚’æ–°é ˜åŸŸã¸å¿œç”¨ã—ã¾ã™ã€‚\n"
        "ã‚³ã‚¢ãƒãƒªãƒ¥ãƒ¼ã‚’ä¿ã¡ãªãŒã‚‰ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢å¸‚å ´ã¸äº‹æ¥­ã‚’åºƒã’ã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£å¼·åŒ–å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "é«˜å“è³ªã¸ã®ã“ã ã‚ã‚Šã‚’ã•ã‚‰ã«ç£¨ãæ—¢å­˜è£½å“ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n"
        "å®‰å…¨æ€§ã‚’æ ¸ã«æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¾ã™ã€‚"
    ),
    "ãã®ä»–ï¼ˆOtherï¼‰": ""
}
label_options = list(category_definitions.keys())

# åˆå§‹åŒ–
if "data" not in st.session_state:
    st.session_state.data = None
if "current_index" not in st.session_state:
    st.session_state.current_index = 0
if "annotations" not in st.session_state:
    st.session_state.annotations = []

st.title("ğŸ“Š æ—¥æœ¬èªï¼šä¼æ¥­å¹´å ±æ–‡ã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡ï¼ˆæ¨™è¨»å”ä½œç‰ˆï¼‰")

# æ–°å¢ï¼šæ¨™è¨»äººå“¡è¼¸å…¥æ¬„
annotator = st.text_input("âœï¸ æ¨™è¨»äººå“¡åç¨±ï¼ˆå°‡è¨˜éŒ„åœ¨æ¯ç­†è³‡æ–™ä¸­ï¼‰", value="åŒ¿å")

# ä¸Šå‚³ Excel
uploaded_file = st.file_uploader("Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.session_state.data = df
    col_name = st.selectbox("â–¶ï¸ åˆ†é¡å¯¾è±¡ã®åˆ—ã‚’é¸æŠ", df.columns.tolist())

    if col_name:
        current = st.session_state.current_index
        total = len(df)

        # é¡¯ç¤ºé€²åº¦æ¢
        st.markdown(f"â³ æ¨™è¨»é€²åº¦ï¼š{current + 1} / {total}")
        st.progress((current + 1) / total)

        if current >= total:
            st.success("âœ… ã™ã¹ã¦ã®æ–‡ã‚’åˆ†é¡ã—ã¾ã—ãŸï¼")
            result_df = pd.DataFrame(st.session_state.annotations)
            st.dataframe(result_df)
            csv = result_df.to_csv(index=False).encode("utf-8")
            st.download_button("ğŸ“¥ åˆ†é¡çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, "classified_results.csv", "text/csv")
        else:
            row = df.iloc[current]
            sentence = str(row[col_name])

            st.markdown("### ğŸ§¾ å‚è€ƒæƒ…å ±")
            for k, v in row.items():
                if k != col_name:
                    st.write(f"**{k}**: {v}")

            st.markdown("### âœï¸ åˆ†é¡å¯¾è±¡ã®æ–‡")
            st.info(sentence)

            # æ¨¡å‹åˆ†é¡é æ¸¬
            sentence_emb = model.encode(sentence, convert_to_tensor=True)
            definition_embs = {
                label: model.encode(
                    [t.strip() for t in text.splitlines() if t.strip()],
                    convert_to_tensor=True
                ).mean(dim=0)
                for label, text in category_definitions.items() if text.strip()
            }

            if sentence.strip() == "" or any(kw in sentence for kw in ["ã€", "ã€‘", "æ™¯æ°—", "ç‚ºæ›¿", "GDP"]):
                predicted_label = "ãã®ä»–ï¼ˆOtherï¼‰"
                best_score = 0.0
                explanation = "å¤–éƒ¨ç’°å¢ƒã‚„æ§‹é€ èªå¥ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‡ªå‹•çš„ã«ã€ãã®ä»–ã€ã¨åˆ†é¡ã•ã‚Œã¾ã—ãŸã€‚"
            else:
                scores = {k: float(util.cos_sim(sentence_emb, v)) for k, v in definition_embs.items()}
                sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
                predicted_label, best_score = sorted_scores[0]
                second_label, second_score = sorted_scores[1]
                example = "\n".join(f"ãƒ»{s}" for s in category_definitions[predicted_label].splitlines()[:2])
                explanation = (
                    f"ã“ã®æ–‡ã¯ã€{predicted_label}ã€ã«æœ€ã‚‚é«˜ã„é¡ä¼¼åº¦ï¼ˆ{best_score:.2f}ï¼‰ã‚’ç¤ºã—ã¾ã—ãŸã€‚\n"
                    f"æ¬¡ã«è¿‘ã„ã®ã¯ã€{second_label}ã€ï¼ˆ{second_score:.2f}ï¼‰ã§ã—ãŸã€‚\n\n"
                    f"ã€Šå‚è€ƒï¼šã€{predicted_label}ã€ã®å®šç¾©æ–‡ä¾‹ã€‹\n{example}"
                )

            with st.expander("ğŸ§  åˆ†é¡ç†ç”±ã‚’è¦‹ã‚‹", expanded=True):
                st.markdown(explanation)

            selected_label = st.selectbox("ğŸ“Œ åˆ†é¡ãƒ©ãƒ™ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", label_options, index=label_options.index(predicted_label))

            if st.button("âœ… ã“ã®æ–‡ã‚’ä¿å­˜ã—ã¦æ¬¡ã¸"):
                annotated = {
                    "index": current,
                    "æ–‡": sentence,
                    "ãƒ¢ãƒ‡ãƒ«åˆ†é¡": predicted_label,
                    "ç›¸ä¼¼åº¦ã‚¹ã‚³ã‚¢": best_score,
                    "ä¿®æ­£å¾Œãƒ©ãƒ™ãƒ«": selected_label,
                    "æ¨™è¨»äººå“¡": annotator,
                }
                for k, v in row.items():
                    annotated[k] = v
                st.session_state.annotations.append(annotated)
                st.session_state.current_index += 1
                st.rerun()
