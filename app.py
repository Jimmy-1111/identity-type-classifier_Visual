import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util

# === æ¨¡å‹è¼‰å…¥ï¼šæŒ‡å®šä½¿ç”¨ CPU é¿å…éƒ¨ç½²å•é¡Œ ===
model = SentenceTransformer("sonoisa/sentence-bert-base-ja-mean-tokens", device="cpu")

# === é¡å‹å®šç¾©ï¼šæ¯é¡ä¸‰å¥ï¼ˆå¯è‡ªè¡Œå¢æ¸›ï¼‰===
default_definitions = {
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŒ‘æˆ¦å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ç§ãŸã¡ã¯ãƒ¢ãƒ“ãƒªãƒ†ã‚£ã‚µãƒ¼ãƒ“ã‚¹ä¼æ¥­ã¸ã¨è»¢æ›ã—ã¾ã™ã€‚\n"
        "æ–°ã—ã„ç¤¾ä¼šèª²é¡Œã«æŒ‘ã‚€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ä¼æ¥­ã¸ç”Ÿã¾ã‚Œå¤‰ã‚ã‚Šã¾ã™ã€‚\n"
        "å½“ç¤¾ã®ä½¿å‘½ã‚’å†å®šç¾©ã—ã€ãƒ‡ã‚¸ã‚¿ãƒ«æ™‚ä»£ã®ä¾¡å€¤å‰µé€ ä¼æ¥­ã¨ãªã‚Šã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ‹¡å¼µå‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ä¼çµ±ã®æŠ€è¡“åŠ›ã‚’æ–°é ˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¸å¿œç”¨ã—ã¾ã™ã€‚\n"
        "ã‚³ã‚¢ãƒãƒªãƒ¥ãƒ¼ã‚’ä¿ã¡ãªãŒã‚‰ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢å¸‚å ´ã¸äº‹æ¥­ã‚’åºƒã’ã¾ã™ã€‚\n"
        "ã‚‚ã®ã¥ãã‚Šç²¾ç¥ã‚’IoTã‚µãƒ¼ãƒ“ã‚¹ã«èåˆã•ã›ã€æ–°ãŸãªä¾¡å€¤ã‚’æä¾›ã—ã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£å¼·åŒ–å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "é«˜å“è³ªã¸ã®ã“ã ã‚ã‚Šã‚’ã•ã‚‰ã«ç£¨ãæ—¢å­˜è£½å“ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n"
        "ç’°å¢ƒå¿—å‘ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚è³‡æºå¾ªç’°å‹å·¥ç¨‹ã‚’å°å…¥ã—ã¾ã™ã€‚\n"
        "é•·å¹´åŸ¹ã£ãŸå®‰å…¨æ€§ã‚’æ ¸ã«æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¾ã™ã€‚"
    ),
    "ä¼çµ±çš„ï¼ä¸­ç«‹çš„è¨€èª": (
        "ç”Ÿç”£åŠ¹ç‡ã‚’7%å‘ä¸Šã•ã›ã‚‹æ”¹å–„æ´»å‹•ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚\n"
        "ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã«ã‚ˆã‚Šå–¶æ¥­åˆ©ç›Šç‡ãŒä¸Šæ˜‡ã—ã¾ã—ãŸã€‚\n"
        "å“è³ªç®¡ç†ä½“åˆ¶ã‚’å†æ§‹ç¯‰ã—ä¸è‰¯ç‡ã‚’å‰Šæ¸›ã—ã¾ã—ãŸã€‚"
    ),
    "ãã®ä»–ï¼ˆOtherï¼‰": (
        "ç¬¬ï¼’ã€äº‹æ¥­ã®çŠ¶æ³ã€‘\n"
        "å›³ï¼‘ï¼šåç›Šã®æ¨ç§»\n"
        "æ³¨è¨˜ï¼šæœ¬è³‡æ–™ã¯ç›£æŸ»æ³•äººã®ç¢ºèªã‚’å—ã‘ã¦ã„ã¾ã™ã€‚\n"
        "ç›®æ¬¡\n"
        "ä»¥ä¸Š"
    )
}

# === é é¢è¨­å®š ===
st.set_page_config(page_title="æ—¥æœ¬èªå¥å­åˆ†é¡", layout="centered")
st.title("ğŸ“Š æ—¥æœ¬èªï¼šä¼æ¥­å¹´å ±æ–‡ã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡")

# === é¡å‹å®šç¾©è¼¸å…¥ï¼ˆå¯å¤šè¡Œï¼‰===
st.header("ğŸ“ åˆ†é¡åŸºæº–ã®å®šç¾©æ–‡ï¼ˆã‚«ãƒ†ã‚´ãƒªã”ã¨ã«è¤‡æ•°è¡Œã§å…¥åŠ›ï¼‰")
category_inputs = {}
for cat, default in default_definitions.items():
    category_inputs[cat] = st.text_area(
        cat,
        value=default,
        height=90,
        help="æ”¹è¡Œã”ã¨ã«åˆ¥ã®å®šç¾©æ–‡ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™"
    )

# === å¥å­è¼¸å…¥ ===
st.header("âœï¸ åˆ†æå¯¾è±¡ã®æ–‡ã‚’å…¥åŠ›ï¼ˆ1 è¡Œ 1 æ–‡ï¼‰")
sentences_text = st.text_area("ã“ã“ã«æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=220)

# === åˆ†ææŒ‰éˆ• ===
if st.button("ğŸš€ åˆ†æã™ã‚‹"):

    sentences = [s.strip() for s in sentences_text.splitlines() if s.strip()]
    if not sentences:
        st.warning("æ–‡ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)

    # === é¡å‹å®šç¾©å¥å‘é‡å¹³å‡ ===
    definition_embeddings = {}
    for label, text_block in category_inputs.items():
        defs = [t.strip() for t in text_block.splitlines() if t.strip()]
        if not defs:
            defs = default_definitions[label].splitlines()
        emb = model.encode(defs, convert_to_tensor=True).mean(dim=0)
        definition_embeddings[label] = emb

    # === åˆ†é¡ä¸»é‚è¼¯ ===
    predicted_labels, similarity_scores = [], []
    threshold = 0.75  # å¯èª¿æ•´

    def is_force_other(sent):
        return "ã€" in sent or "ã€‘" in sent

    for sent, sent_emb in zip(sentences, sentence_embeddings):
        # è‹¥å«æœ‰ã€æˆ–ã€‘â†’ å¼·åˆ¶æ­¸ç‚ºã€Œå…¶ä»–ã€
        if is_force_other(sent):
            predicted_labels.append("ãã®ä»–ï¼ˆOtherï¼‰")
            similarity_scores.append(0.0)
            continue

        # å¦å‰‡ç…§å¸¸èªæ„åˆ†é¡
        scores = {
            label: float(util.cos_sim(sent_emb, def_emb))
            for label, def_emb in definition_embeddings.items()
        }
        best_label = max(scores, key=scores.get)
        best_score = scores[best_label]

        if best_score < threshold:
            predicted_labels.append("ãã®ä»–ï¼ˆOtherï¼‰")
        else:
            predicted_labels.append(best_label)
        similarity_scores.append(best_score)

    # === é¡¯ç¤ºçµæœ ===
    result_df = pd.DataFrame({
        "å…¥åŠ›æ–‡": sentences,
        "åˆ†é¡ãƒ©ãƒ™ãƒ«": predicted_labels,
        "similarity score": similarity_scores
    })
    st.subheader("ğŸ” åˆ†æçµæœ")
    st.dataframe(result_df, use_container_width=True)
