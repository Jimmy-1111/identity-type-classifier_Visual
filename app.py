import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import torch

# === æ¨¡å‹è¼‰å…¥ ===
model = SentenceTransformer("sonoisa/sentence-bert-base-ja-mean-tokens")
model.to(torch.device("cpu"))

# === åˆ†é¡å®šç¾©æ–‡ ===
default_definitions = {
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŒ‘æˆ¦å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ç§ãŸã¡ã¯ãƒ¢ãƒ“ãƒªãƒ†ã‚£ã‚µãƒ¼ãƒ“ã‚¹ä¼æ¥­ã¸ã¨è»¢æ›ã—ã¾ã™ã€‚\n"
        "æ–°ã—ã„ç¤¾ä¼šèª²é¡Œã«æŒ‘ã‚€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ä¼æ¥­ã¸ç”Ÿã¾ã‚Œå¤‰ã‚ã‚Šã¾ã™ã€‚\n"
        "å½“ç¤¾ã®ä½¿å‘½ã‚’å†å®šç¾©ã—ã€ãƒ‡ã‚¸ã‚¿ãƒ«æ™‚ä»£ã®ä¾¡å€¤å‰µé€ ä¼æ¥­ã¨ãªã‚Šã¾ã™ã€‚\n"
        "æ–°ã—ã„ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç¢ºç«‹ã‚’ç›®æŒ‡ã—ã¦ã€æ–°ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’å±•é–‹ã—ã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ‹¡å¼µå‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "ä¼çµ±ã®æŠ€è¡“åŠ›ã‚’æ–°é ˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¸å¿œç”¨ã—ã¾ã™ã€‚\n"
        "ã‚³ã‚¢ãƒãƒªãƒ¥ãƒ¼ã‚’ä¿ã¡ãªãŒã‚‰ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢å¸‚å ´ã¸äº‹æ¥­ã‚’åºƒã’ã¾ã™ã€‚\n"
        "ã‚‚ã®ã¥ãã‚Šç²¾ç¥ã‚’IoTã‚µãƒ¼ãƒ“ã‚¹ã«èåˆã•ã›ã€æ–°ãŸãªä¾¡å€¤ã‚’æä¾›ã—ã¾ã™ã€‚"
    ),
    "ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£å¼·åŒ–å‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³": (
        "é«˜å“è³ªã¸ã®ã“ã ã‚ã‚Šã‚’ã•ã‚‰ã«ç£¨ãæ—¢å­˜è£½å“ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n"
        "ç’°å¢ƒå¿—å‘ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚è³‡æºå¾ªç’°å‹å·¥ç¨‹ã‚’å°å…¥ã—ã¾ã™ã€‚\n"
        "é•·å¹´åŸ¹ã£ãŸå®‰å…¨æ€§ã‚’æ ¸ã«æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¾ã™ã€‚"
    ),
    "ä¼çµ±çš„ï¼ä¸­ç«‹çš„è¨€èª": (
        "ç”Ÿç”£åŠ¹ç‡ã‚’7%å‘ä¸Šã•ã›ã‚‹æ”¹å–„æ´»å‹•ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚\n"
        "ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã«ã‚ˆã‚Šå–¶æ¥­åˆ©ç›Šç‡ãŒä¸Šæ˜‡ã—ã¾ã—ãŸã€‚\n"
        "å“è³ªç®¡ç†ä½“åˆ¶ã‚’å†æ§‹ç¯‰ã—ä¸è‰¯ç‡ã‚’å‰Šæ¸›ã—ã¾ã—ãŸã€‚"
    )
}
label_options = list(default_definitions.keys()) + ["ãã®ä»–ï¼ˆOtherï¼‰"]

EXTERNAL_ONLY_KEYWORDS = [
    "çµŒæ¸ˆ", "æ™¯æ°—", "ã‚¤ãƒ³ãƒ•ãƒ¬", "é‡‘åˆ©", "ç‚ºæ›¿", "ç‰©ä¾¡", "æ”¿ç­–", "åœ°æ”¿å­¦",
    "å€‹äººæ¶ˆè²»", "ä¸­å¤®éŠ€è¡Œ", "æ¶ˆè²»è€…å¿ƒç†", "æŠ•è³‡ç’°å¢ƒ", "è¼¸å‡º", "è¼¸å…¥", "GDP", "æ™¯æ³æ„Ÿ"
]

def is_force_other(sent):
    return "ã€" in sent or "ã€‘" in sent or any(kw in sent for kw in EXTERNAL_ONLY_KEYWORDS)

# === Streamlit é é¢è¨­å®š ===
st.set_page_config(page_title="ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡", layout="centered")
st.title("ğŸ“Š æ—¥æœ¬èªï¼šä¼æ¥­å¹´å ±æ–‡ã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡")

# === åˆå§‹åŒ–ç‹€æ…‹ ===
if "results" not in st.session_state:
    st.session_state.results = None

st.header("ğŸ–Šï¸ åˆ†æå¯¾è±¡ã®æ–‡ã‚’å…¥åŠ›ï¼ˆ1 è¡Œ 1 æ–‡ï¼‰")
sentences_text = st.text_area("ã“ã“ã«æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=220)

# === åˆ†ææŒ‰éˆ• ===
if st.button("ğŸš€ åˆ†æã™ã‚‹"):
    sentences = [s.strip() for s in sentences_text.splitlines() if s.strip()]
    if not sentences:
        st.warning("æ–‡ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)
    definition_embeddings = {
        label: model.encode(
            [t.strip() for t in text.splitlines() if t.strip()],
            convert_to_tensor=True
        ).mean(dim=0)
        for label, text in default_definitions.items()
    }

    data = []
    for i, (sent, emb) in enumerate(zip(sentences, sentence_embeddings)):
        if is_force_other(sent):
            pred_label = "ãã®ä»–ï¼ˆOtherï¼‰"
            score = 0.0
        else:
            scores = {k: float(util.cos_sim(emb, v)) for k, v in definition_embeddings.items()}
            sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
            pred_label, score = sorted_scores[0]

        data.append({
            "å…¥åŠ›æ–‡": sent,
            "åˆ†é¡ãƒ©ãƒ™ãƒ«": pred_label,
            "similarity score": score,
            "ä¿®æ­£å¾Œãƒ©ãƒ™ãƒ«": pred_label
        })

    st.session_state.results = data  # å„²å­˜åˆ†æçµæœ

# === é¡¯ç¤ºçµæœèˆ‡åˆ†é¡ä¿®æ­£ ===
if st.session_state.results:
    st.subheader("âœï¸ åˆ†é¡ã®ä¿®æ­£ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰")
    for i, row in enumerate(st.session_state.results):
        st.markdown(f"**æ–‡ {i+1}ï¼š** {row['å…¥åŠ›æ–‡']}")
        new_label = st.selectbox(
            "åˆ†é¡ãƒ©ãƒ™ãƒ«ã‚’ä¿®æ­£ã™ã‚‹ï¼ˆã¾ãŸã¯ãã®ã¾ã¾ï¼‰",
            label_options,
            index=label_options.index(row["ä¿®æ­£å¾Œãƒ©ãƒ™ãƒ«"]),
            key=f"label_select_{i}"
        )
        st.session_state.results[i]["ä¿®æ­£å¾Œãƒ©ãƒ™ãƒ«"] = new_label

    # åŒ¯å‡ºè¡¨æ ¼
    result_df = pd.DataFrame(st.session_state.results)
    st.subheader("ğŸ“¥ ä¿®æ­£å¾Œã®çµæœä¸€è¦§")
    st.dataframe(result_df[["å…¥åŠ›æ–‡", "åˆ†é¡ãƒ©ãƒ™ãƒ«", "ä¿®æ­£å¾Œãƒ©ãƒ™ãƒ«", "similarity score"]], use_container_width=True)

    csv = result_df.to_csv(index=False).encode("utf-8")
    st.download_button("ğŸ“¥ ä¿®æ­£çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, "classified_results.csv", "text/csv")
